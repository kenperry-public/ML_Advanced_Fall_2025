{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\\newcommand{\\x}{\\mathbf{x}}\n",
       "\\newcommand{\\tx}{\\tilde{\\x}}\n",
       "\\newcommand{\\y}{\\mathbf{y}}\n",
       "\\newcommand{\\b}{\\mathbf{b}}\n",
       "\\newcommand{\\c}{\\mathbf{c}}\n",
       "\\newcommand{\\e}{\\mathbf{e}}\n",
       "\\newcommand{\\z}{\\mathbf{z}}\n",
       "\\newcommand{\\h}{\\mathbf{h}}\n",
       "\\newcommand{\\u}{\\mathbf{u}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\w}{\\mathbf{w}}\n",
       "\\newcommand{\\V}{\\mathbf{V}}\n",
       "\\newcommand{\\W}{\\mathbf{W}}\n",
       "\\newcommand{\\X}{\\mathbf{X}}\n",
       "\\newcommand{\\KL}{\\mathbf{KL}}\n",
       "\\newcommand{\\E}{{\\mathbb{E}}}\n",
       "\\newcommand{\\Reals}{{\\mathbb{R}}}\n",
       "\\newcommand{\\ip}{\\mathbf{{(i)}}}\n",
       "%\n",
       "% Test set\n",
       "\\newcommand{\\xt}{\\underline{\\x}}\n",
       "\\newcommand{\\yt}{\\underline{\\y}}\n",
       "\\newcommand{\\Xt}{\\underline{\\X}}\n",
       "\\newcommand{\\perfm}{\\mathcal{P}}\n",
       "%\n",
       "% \\ll indexes a layer; we can change the actual letter\n",
       "\\newcommand{\\ll}{l}\n",
       "\\newcommand{\\llp}{{(\\ll)}}\n",
       "%\n",
       "\\newcommand{Thetam}{\\Theta_{-0}}\n",
       "\n",
       "% CNN\n",
       "\\newcommand{\\kernel}{\\mathbf{k}} \n",
       "\\newcommand{\\dim}{d}\n",
       "\\newcommand{\\idxspatial}{{\\text{idx}}}\n",
       "\\newcommand{\\summaxact}{\\text{max}}\n",
       "\\newcommand{idxb}{\\mathbf{i}}\n",
       "%\n",
       "%\n",
       "\n",
       "% RNN\n",
       "% \\tt indexes a time step\n",
       "\\newcommand{\\tt}{t}\n",
       "\\newcommand{\\tp}{{(\\tt)}}\n",
       "%\n",
       "%\n",
       "\n",
       "% LSTM\n",
       "\\newcommand{\\g}{\\mathbf{g}}\n",
       "\\newcommand{\\remember}{\\mathbf{remember}}\n",
       "\\newcommand{\\save}{\\mathbf{save}}\n",
       "\\newcommand{\\focus}{\\mathbf{focus}}\n",
       "%\n",
       "%\n",
       "% NLP\n",
       "\\newcommand{\\Vocab}{\\mathbf{V}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\offset}{o}\n",
       "\\newcommand{\\o}{o}\n",
       "\\newcommand{\\Emb}{\\mathbf{E}}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\loss}{\\mathcal{L}}\n",
       "\\newcommand{\\cost}{\\mathcal{L}}\n",
       "%\n",
       "%                     \n",
       "\\newcommand{\\pdata}{p_\\text{data}}\n",
       "\\newcommand{\\pmodel}{p_\\text{model}}\n",
       "%\n",
       "% SVM\n",
       "\\newcommand{\\margin}{{\\mathbb{m}}}\n",
       "\\newcommand{\\lmk}{\\boldsymbol{\\ell}}\n",
       "%\n",
       "%\n",
       "% LLM Reasoning\n",
       "\\newcommand{\\rat}{\\mathbf{r}}\n",
       "\\newcommand{\\model}{\\mathcal{M}}\n",
       "\\newcommand{\\bthink}{\\text{<think>}}\n",
       "\\newcommand{\\ethink}{\\text{</think>}}\n",
       "%\n",
       "%\n",
       "% Functions with arguments\n",
       "\\def\\xsy#1#2{#1^#2}\n",
       "\\def\\rand#1{\\tilde{#1}}\n",
       "\\def\\randx{\\rand{\\x}}\n",
       "\\def\\randy{\\rand{\\y}}\n",
       "\\def\\trans#1{\\dot{#1}}\n",
       "\\def\\transx{\\trans{\\x}}\n",
       "\\def\\transy{\\trans{\\y}}\n",
       "%\n",
       "\\def\\argmax#1{\\underset{#1} {\\operatorname{argmax}} }\n",
       "\\def\\argmin#1{\\underset{#1} {\\operatorname{argmin}} }\n",
       "\\def\\max#1{\\underset{#1} {\\operatorname{max}} }\n",
       "\\def\\min#1{\\underset{#1} {\\operatorname{min}} }\n",
       "%\n",
       "\\def\\pr#1{\\mathcal{p}(#1)}\n",
       "\\def\\prc#1#2{\\mathcal{p}(#1 \\; | \\; #2)}\n",
       "\\def\\cnt#1{\\mathcal{count}_{#1}}\n",
       "\\def\\node#1{\\mathbb{#1}}\n",
       "%\n",
       "\\def\\loc#1{{\\text{##} {#1}}}\n",
       "%\n",
       "\\def\\OrderOf#1{\\mathcal{O}\\left( {#1} \\right)}\n",
       "%\n",
       "% Expectation operator\n",
       "\\def\\Exp#1{\\underset{#1} {\\operatorname{\\mathbb{E}}} }\n",
       "%\n",
       "% VAE\n",
       "\\def\\prs#1#2{\\mathcal{p}_{#2}(#1)}\n",
       "\\def\\qr#1{\\mathcal{q}(#1)}\n",
       "\\def\\qrs#1#2{\\mathcal{q}_{#2}(#1)}\n",
       "%\n",
       "% Reinforcement learning\n",
       "\\newcommand{\\Actions}{{\\mathcal{A}}} \n",
       "\\newcommand{\\actseq}{A}\n",
       "\\newcommand{\\act}{a}\n",
       "\\newcommand{\\States}{{\\mathcal{S}}}   \n",
       "\\newcommand{\\stateseq}{S}  \n",
       "\\newcommand{\\state}{s}\n",
       "\\newcommand{\\Rewards}{{\\mathcal{R}}}\n",
       "\\newcommand{\\rewseq}{R}\n",
       "\\newcommand{\\rew}{r}\n",
       "\\newcommand{\\transp}{P}\n",
       "\\newcommand{\\statevalfun}{v}\n",
       "\\newcommand{\\actvalfun}{q}\n",
       "\\newcommand{\\disc}{\\gamma}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\floor}[1]{\\left\\lfloor #1 \\right\\rfloor}\n",
       "\\newcommand{\\ceil}[1]{\\left\\lceil #1 \\right\\rceil}\n",
       "%\n",
       "%\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run Latex_macros.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "**References**\n",
    "- [SELF-Instruct paper](https://arxiv.org/pdf/2212.10560.pdf)\n",
    "- [Self-Alignment with Instruction Backtranslation](https://arxiv.org/pdf/2308.06259.pdf)\n",
    "- [Large Language Models can Self-Improve](https://arxiv.org/pdf/2210.11610.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using an LLM to generate Instruction Following examples\n",
    "\n",
    "In the module on [Instruction Following](LLM_Instruction_Following.ipynb)\n",
    "- we motivated the use of Fine-Tuning a LLM\n",
    "- to exhibit Instruction Following behavior\n",
    "\n",
    "Recall: an example of Instruction Following behavior is a triple\n",
    "\n",
    "$$\\langle \\text{Instruction}, \\text{Context}, \\text{Response} \\rangle $$\n",
    "\n",
    "for example\n",
    "- Instruction: \"Tell me the word that is the opposite of the word that I input\"\n",
    "- Context: \"Input: Stop\"\n",
    "- Response: \"Go\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The Instruction describes the task to be accomplished\n",
    "- relationship between Input and Response\n",
    "- the Input/Response pair is an exemplar for this task\n",
    "\n",
    "In this module, we explore methods\n",
    "- to generate these fine-tuning examples\n",
    "- to improve examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using an LLM to generate Instruction Following examples\n",
    "\n",
    "**Reference**\n",
    "\n",
    "[SELF-Instruct paper](https://arxiv.org/pdf/2212.10560.pdf)\n",
    "\n",
    "Is there an alternative to the labor-intensity of constructing Instruction Following examples by human ?\n",
    "\n",
    "These examples are pairs of an Instruction part, and a Target Output part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The idea of the [SELF-Instruct paper](https://arxiv.org/pdf/2212.10560.pdf)\n",
    "is to create Synthetic examples\n",
    "- using [In-Context Learning](In_Context_Learning.ipynb)\n",
    "\n",
    "We can imagine the process as\n",
    "- starting with a small number $k$ of human-constructed examples\n",
    "\n",
    "$$\n",
    "\\begin{array}[lll] \\\\\n",
    "\\langle \\text{Instruction}^{(1)}, \\text{Context}^{(1)}, \\text{Response}^{(1)} \\rangle \\\\\n",
    "\\vdots \\\\\n",
    "\\langle \\text{Instruction}^{(k)}, \\text{Context}^{(k)}, \\text{Response}^{(k)} \\rangle \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "- which are used as exemplars\n",
    "- in a *few-shot* learning prompt\n",
    "- that an LLM completes into a new Instruction Following example\n",
    "\n",
    "$$\n",
    "\\langle \\text{Instruction}^{(k+1)}, \\text{Context}^{(k+1)}, \\text{Response}^{(k+1)} \\rangle \\\\\n",
    "$$\n",
    "\n",
    "The human and LLM generated examples can then be used to Fine Tune an LLM to better demonstrate Instruction Following"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In actuality\n",
    "- the Instruction part of the triple \n",
    "\n",
    "$$\n",
    "\\langle \\text{Instruction}^{(k+1)}, \\text{Context}^{(k+1)}, \\text{Response}^{(k+1)} \\rangle \\\\\n",
    "$$\n",
    "\n",
    "- is generated first\n",
    "- using In-Context learning\n",
    "\n",
    "Given the newly generated instruction $$\\text{Instruction}^{(k+1)}$$\n",
    "- In-Context learning is used again\n",
    "- to generate the associated Context and Response $$\\text{Context}^{(k+1)}, \\text{Response}^{(k+1)} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The process for generating each part of the triple \n",
    "- is illustrated by a diagram\n",
    "- with the steps described in detail below\n",
    "<br>\n",
    "<img src=\"images/selfinstruct_process.png\">\n",
    "\n",
    "Attribution: https://arxiv.org/pdf/2212.10560.pdf#page=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generating the Instruction part of an Instruction-Output example\n",
    "\n",
    "The first step is to generate the  first Instruction part (i.e., the Instruction) of the triple\n",
    "\n",
    "$$\n",
    "\\langle \\textbf{Instruction}^{(k+1)}, \\text{Context}^{(k+1)}, \\text{Response}^{(k+1)} \\rangle \\\\\n",
    "$$\n",
    "\n",
    "using $k$ exemplars\n",
    "$$\n",
    "\\begin{array}[lll] \\\\\n",
    "\\langle \\text{Instruction}^{(1)} \\rangle \\\\\n",
    "\\vdots \\\\\n",
    "\\langle \\text{Instruction}^{(k)} \\rangle \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "**See the box labeled \"Step 1\" in the illustration above**\n",
    "\n",
    "The precise template for the exemplars is show below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "<img src=\"images/selfinstruct_task_generation_prompts.png\" width=90%>\n",
    "\n",
    "Attribution: https://arxiv.org/pdf/2212.10560.pdf#page=15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "With the above template, we expect the LLM\n",
    "- to generate a continuation of the prompt \n",
    "    - ending with `Task 9: `\n",
    "- which is the Instruction part of a new task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generating the Context/Respones (Input/Output) part, given an Instruction\n",
    "\n",
    "Once we have generated a the Instruction part\n",
    "$$\\text{Instruction}^{(k+1)}$$\n",
    "\n",
    "of the new synthetic example, we need to generate the Context and Response\n",
    "- using exemplars\n",
    "\n",
    "$$\n",
    "\\begin{array}[lll] \\\\\n",
    "\\langle \\text{Instruction}^{(1)}, \\text{Context}^{(1)}, \\text{Response}^{(1)} \\rangle \\\\\n",
    "\\vdots \\\\\n",
    "\\langle \\text{Instruction}^{(k)}, \\text{Context}^{(k)}, \\text{Response}^{(k)} \\rangle \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "and prompt\n",
    "$$\n",
    "\\text{Instruction}^{(k+1)}\n",
    "$$\n",
    "\n",
    "with the expectation that the LLM's continuation will be\n",
    "$$\n",
    "\\text{Context}^{(k+1)}, \\text{Response}^{(k+1)}\n",
    "$$\n",
    "\n",
    "\n",
    "**See the box labeled \"Step 3\" in the diagram above**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For Classification tasks, the prompt might look like this\n",
    "\n",
    "    Task: Classify the sentiment of the sentence into positive, negative, or mixed\n",
    "    \n",
    "    Example 1\n",
    "    Sentence: I enjoy the flavor of the restaurant but their service is too slow.\n",
    "    Class Label: mixed\n",
    "    \n",
    "    Example 2\n",
    "    Sentence: I had a great day today. The weather was beautiful and I spent time with friends.\n",
    "    Class label: Positive\n",
    "    \n",
    "    \n",
    "    Task: Tell me if the following email is a promotion email or not.\n",
    "    \n",
    "    Email: Check out our amazing new sale! Weâ€™ve got discounts on all of your favorite products.\n",
    "    Class label: Promotion\n",
    "\n",
    "    Email: We hope you are doing well. Let us know if you need any help.\n",
    "    Class label: Not Promotion\n",
    "    \n",
    "    Task: {instruction for the target task}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The last line above contains a place holder for the Instruction of the Target Task\n",
    "\n",
    "$$\n",
    "\\text{Instruction}^{(k+1)}\n",
    "$$\n",
    "\n",
    "that we created in Step 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here is an example of the template from the paper\n",
    "\n",
    "<img src=\"images/selfinstruct_generated_instances.png\">\n",
    "\n",
    "Attribution: https://arxiv.org/pdf/2212.10560.pdf#page=16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Difficulties in Generating the Input/Output part: Classification tasks\n",
    "\n",
    "Although the few-shot learning approach to generating an Input/Output given an Instruction \n",
    "- seems straightforward\n",
    "- the authors encountered difficulties when generating Input/Output for Classification tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Consider the an Instruction Following example for a Classification task\n",
    "\n",
    "    Task: Classify the sentiment of the sentence into positive, negative, or mixed\n",
    "    \n",
    "    Example 1\n",
    "    Sentence: I enjoy the flavor of the restaurant but their service is too slow.\n",
    "    Class Label: mixed\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The authors found that the response generated by the LLM (e.g., Classification examples)\n",
    "- were examples whose Class Label's \n",
    "- were *not well-distributed* among all possible labels \n",
    "    - examples with certain labels were either over or under represented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This was attributed to the *format* of the example called *Input-first* format\n",
    "$$\n",
    "\\langle \\text{Instruction}^{(i)}, \\text{Context}^{(i)}, \\text{Response}^{(i)} \\rangle\n",
    "$$\n",
    "\n",
    "where \n",
    "- $\\text{Context}^{(i)}$ is the `Additional Input`\n",
    "- $\\text{Response}^{(i)}$ is the `Class label`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The solution was to change the example format to *output-first*\n",
    "$$\n",
    "\\langle \\text{Instruction}^{(i)},  \\text{Response}^{(i)}, \\text{Context}^{(i)} \\rangle\n",
    "$$\n",
    "\n",
    "where the Response (`Class label`) **precedes** the Context (`Additional Input`)\n",
    "\n",
    "For example:\n",
    "\n",
    "     Task: Classify the sentiment of the sentence into positive, negative, or mixed\n",
    "\n",
    "     Example 1\n",
    "        Class Label: mixed\n",
    "        Sentence: I enjoy the flavor of the restaurant but their service is too slow.\n",
    "        \n",
    "\n",
    "        Example 2\n",
    "        Class label: Positive\n",
    "        Sentence: I had a great day today. The weather was beautiful and I spent time with friends.\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This is an example of Prompt Engineering\n",
    "- In-context learning seems very sensitive to the format of prompts\n",
    "- There is a skill of engineering a prompt to elicit the desired behavior\n",
    "\n",
    "This feels similar to the idea behind Chain of Thought prompting\n",
    "- by presenting `Class Label` first\n",
    "- the model seems better conditioned to generate a less biased distribution of labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Generating Instructions via  Backtranslation\n",
    "\n",
    "We now present an alternate method for generating the Instruction part of \n",
    "$$\n",
    "\\langle \\text{Instruction} \\rangle\n",
    "$$\n",
    "of an Instruction Following example\n",
    "$$\n",
    "\\langle \\text{Instruction}, \\text{Context}, \\text{Response} \\rangle\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The idea seems, at first, to be backwards:\n",
    "- Generate an instance of Instruction Following behavior\n",
    "$$\\langle\\x, \\y \\rangle =  \\langle \\text{Instruction}, \\text{Response} \\rangle$$\n",
    "- by starting with a\n",
    " $\\text{Response}$\n",
    "- and using an LLM to create the $\\text{Instruction}$\n",
    "\n",
    "Essentially\n",
    "- we start with *un-labeled data* (`Response`)\n",
    "- and create a *label* (`Instruction`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The advantage of this approach is that\n",
    "- un-labeled data is plentiful\n",
    "    - almost any block of text\n",
    "- but labeled data ( `Response/Instruction` pairs) is scarce.\n",
    "\n",
    "So, starting with a plentiful resource, we create the scarce resource\n",
    "- i.e, Instruction Following example triplet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The method is called *Back Translation*.\n",
    "\n",
    "- given a *small* \"seed\"  of Instruction/Response pairs\n",
    "$$\\langle\\x, \\y \\rangle =  \\langle \\text{Instruction}, \\text{Response} \\rangle$$\n",
    "- create an inverse dataset of Response/Instruction pairs by reversing the features and targets\n",
    "$$\\langle\\y, \\x \\rangle =  \\langle  \\text{Response}, \\text{Instruction} \\rangle$$\n",
    "\n",
    "We use the inverse dataset to train a model $M_{yz}$\n",
    "- given a Response ($\\y$)\n",
    "- to create an Instruction ($\\z = \\hat\\x$)\n",
    "\n",
    "by fine-tuning an LLM to predict $\\text{Instruction}$ from $\\text{Response}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " $M_{yz}$\n",
    " - when fed by set of Responses $\\{ y_i \\}$\n",
    "     - the Unlabeled Data in the diagram\n",
    " - creates new instances of Instruction/Response examples\n",
    " \n",
    "This results in an enlarged set of Instruction/Response examples\n",
    "- the original human generated examples\n",
    "- augmented by the Synthetic examples creates by  $M_{yz}$\n",
    "\n",
    "in a process called *Self Augmentation*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "With the newly extended set of seed Instruction/Response pairs\n",
    "- we have more exemplars\n",
    "- which we can use as a seed to another iteration of  $M_{yz}$\n",
    "    - the enlarged set of exemplars may result in *better* synthetic Instruction/Response pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can iterate on this process multiple times\n",
    "- using the Augmented set of Instruction/Response pairs from step $i$\n",
    "- as the \"seed\" for iteration $(i +1)$ of the process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here is the workflow:\n",
    "\n",
    "<table>\n",
    "    <center><strong>Instruction Backtranslation</strong></center>\n",
    "    <tr>\n",
    "        <img src=\"images/instruction_backtranslation.png\" width=70%>\n",
    "    </tr>\n",
    "    \n",
    "Attribution: https://arxiv.org/pdf/2308.06259.pdf#page=2\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Selecting the best synthetic examples for augmentation\n",
    "\n",
    "The quality of the synthetic examples created at each step may not be uniformly high.\n",
    "\n",
    "It would be desirable \n",
    "- to select only the best examples to use\n",
    "- in augmenting the seed examples of each iterative Step.\n",
    "\n",
    "How can we rate the quality of a synthetic example ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ask the LLM to do it for you ! \n",
    "\n",
    "Using just the seed data\n",
    "- fine tune a \"first generation\" LLM\n",
    "    - denoted $M_0$\n",
    "- to create a quality score of examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The following prompt requests that the LLM evaluate the\n",
    "synthetic example using a rating scale of $1$ (low quality) to $5$ (high quality)\n",
    "\n",
    "<table>\n",
    "    <center><strong>Instruction Backtranslation Curation</strong></center>\n",
    "    <tr>\n",
    "        <img src=\"images/instruction_backtranslation_curating.png\" width=70%>\n",
    "    </tr>\n",
    "    \n",
    "Attribution: https://arxiv.org/pdf/2308.06259.pdf#page=4\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Use $M_0$ to\n",
    "- select the best first generation augmented examples (from the first iteration)\n",
    "\n",
    "The next generation augmented data set is\n",
    "- the prior generation \n",
    "- augmented with the best (highest quality scores) of the new generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now that we have\n",
    "- an augmented (high quality) \"generation $i$\" set of seed examples\n",
    "\n",
    "we continue our iterative process\n",
    "- creating a more powerful scoring LLM $M_i$\n",
    "- to create an augmented high quality \"generation $i+1$\" set of examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This is an example of [LLM Self-Improvement](LLM_Self_Improvement.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "369.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
