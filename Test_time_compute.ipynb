{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\\newcommand{\\x}{\\mathbf{x}}\n",
       "\\newcommand{\\tx}{\\tilde{\\x}}\n",
       "\\newcommand{\\y}{\\mathbf{y}}\n",
       "\\newcommand{\\b}{\\mathbf{b}}\n",
       "\\newcommand{\\c}{\\mathbf{c}}\n",
       "\\newcommand{\\e}{\\mathbf{e}}\n",
       "\\newcommand{\\z}{\\mathbf{z}}\n",
       "\\newcommand{\\h}{\\mathbf{h}}\n",
       "\\newcommand{\\u}{\\mathbf{u}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\w}{\\mathbf{w}}\n",
       "\\newcommand{\\V}{\\mathbf{V}}\n",
       "\\newcommand{\\W}{\\mathbf{W}}\n",
       "\\newcommand{\\X}{\\mathbf{X}}\n",
       "\\newcommand{\\KL}{\\mathbf{KL}}\n",
       "\\newcommand{\\E}{{\\mathbb{E}}}\n",
       "\\newcommand{\\Reals}{{\\mathbb{R}}}\n",
       "\\newcommand{\\ip}{\\mathbf{{(i)}}}\n",
       "%\n",
       "% Test set\n",
       "\\newcommand{\\xt}{\\underline{\\x}}\n",
       "\\newcommand{\\yt}{\\underline{\\y}}\n",
       "\\newcommand{\\Xt}{\\underline{\\X}}\n",
       "\\newcommand{\\perfm}{\\mathcal{P}}\n",
       "%\n",
       "% \\ll indexes a layer; we can change the actual letter\n",
       "\\newcommand{\\ll}{l}\n",
       "\\newcommand{\\llp}{{(\\ll)}}\n",
       "%\n",
       "\\newcommand{Thetam}{\\Theta_{-0}}\n",
       "\n",
       "% CNN\n",
       "\\newcommand{\\kernel}{\\mathbf{k}} \n",
       "\\newcommand{\\dim}{d}\n",
       "\\newcommand{\\idxspatial}{{\\text{idx}}}\n",
       "\\newcommand{\\summaxact}{\\text{max}}\n",
       "\\newcommand{idxb}{\\mathbf{i}}\n",
       "%\n",
       "%\n",
       "\n",
       "% RNN\n",
       "% \\tt indexes a time step\n",
       "\\newcommand{\\tt}{t}\n",
       "\\newcommand{\\tp}{{(\\tt)}}\n",
       "%\n",
       "%\n",
       "\n",
       "% LSTM\n",
       "\\newcommand{\\g}{\\mathbf{g}}\n",
       "\\newcommand{\\remember}{\\mathbf{remember}}\n",
       "\\newcommand{\\save}{\\mathbf{save}}\n",
       "\\newcommand{\\focus}{\\mathbf{focus}}\n",
       "%\n",
       "%\n",
       "% NLP\n",
       "\\newcommand{\\Vocab}{\\mathbf{V}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\offset}{o}\n",
       "\\newcommand{\\o}{o}\n",
       "\\newcommand{\\Emb}{\\mathbf{E}}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\loss}{\\mathcal{L}}\n",
       "\\newcommand{\\cost}{\\mathcal{L}}\n",
       "%\n",
       "%                     \n",
       "\\newcommand{\\pdata}{p_\\text{data}}\n",
       "\\newcommand{\\pmodel}{p_\\text{model}}\n",
       "%\n",
       "% SVM\n",
       "\\newcommand{\\margin}{{\\mathbb{m}}}\n",
       "\\newcommand{\\lmk}{\\boldsymbol{\\ell}}\n",
       "%\n",
       "%\n",
       "% LLM Reasoning\n",
       "\\newcommand{\\rat}{\\mathbf{r}}\n",
       "\\newcommand{\\model}{\\mathcal{M}}\n",
       "\\newcommand{\\bthink}{\\text{<think>}}\n",
       "\\newcommand{\\ethink}{\\text{</think>}}\n",
       "%\n",
       "%\n",
       "% Functions with arguments\n",
       "\\def\\xsy#1#2{#1^#2}\n",
       "\\def\\rand#1{\\tilde{#1}}\n",
       "\\def\\randx{\\rand{\\x}}\n",
       "\\def\\randy{\\rand{\\y}}\n",
       "\\def\\trans#1{\\dot{#1}}\n",
       "\\def\\transx{\\trans{\\x}}\n",
       "\\def\\transy{\\trans{\\y}}\n",
       "%\n",
       "\\def\\argmax#1{\\underset{#1} {\\operatorname{argmax}} }\n",
       "\\def\\argmin#1{\\underset{#1} {\\operatorname{argmin}} }\n",
       "\\def\\max#1{\\underset{#1} {\\operatorname{max}} }\n",
       "\\def\\min#1{\\underset{#1} {\\operatorname{min}} }\n",
       "%\n",
       "\\def\\pr#1{\\mathcal{p}(#1)}\n",
       "\\def\\prc#1#2{\\mathcal{p}(#1 \\; | \\; #2)}\n",
       "\\def\\cnt#1{\\mathcal{count}_{#1}}\n",
       "\\def\\node#1{\\mathbb{#1}}\n",
       "%\n",
       "\\def\\loc#1{{\\text{##} {#1}}}\n",
       "%\n",
       "\\def\\OrderOf#1{\\mathcal{O}\\left( {#1} \\right)}\n",
       "%\n",
       "% Expectation operator\n",
       "\\def\\Exp#1{\\underset{#1} {\\operatorname{\\mathbb{E}}} }\n",
       "%\n",
       "% VAE\n",
       "\\def\\prs#1#2{\\mathcal{p}_{#2}(#1)}\n",
       "\\def\\qr#1{\\mathcal{q}(#1)}\n",
       "\\def\\qrs#1#2{\\mathcal{q}_{#2}(#1)}\n",
       "%\n",
       "% Reinforcement learning\n",
       "\\newcommand{\\Actions}{{\\mathcal{A}}} \n",
       "\\newcommand{\\actseq}{A}\n",
       "\\newcommand{\\act}{a}\n",
       "\\newcommand{\\States}{{\\mathcal{S}}}   \n",
       "\\newcommand{\\stateseq}{S}  \n",
       "\\newcommand{\\state}{s}\n",
       "\\newcommand{\\Rewards}{{\\mathcal{R}}}\n",
       "\\newcommand{\\rewseq}{R}\n",
       "\\newcommand{\\rew}{r}\n",
       "\\newcommand{\\transp}{P}\n",
       "\\newcommand{\\statevalfun}{v}\n",
       "\\newcommand{\\actvalfun}{q}\n",
       "\\newcommand{\\disc}{\\gamma}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\floor}[1]{\\left\\lfloor #1 \\right\\rfloor}\n",
       "\\newcommand{\\ceil}[1]{\\left\\lceil #1 \\right\\rceil}\n",
       "%\n",
       "%\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run Latex_macros.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Scaling laws: Test time compute\n",
    "\n",
    "At first, it was thought that the way to achieve a high Performance Metric was via\n",
    "using models with a large number of parameters.\n",
    "\n",
    "The Scaling Law showed this to not be true\n",
    "- defines the Performance as a function of number of parameters and number of tokens consumed during training\n",
    "- thus, a small and large model might achieve the same Performance\n",
    "    - with the smaller model needing to consume many more tokens during training\n",
    "\n",
    "But there is another dimension to consider in order to reach a Performance target\n",
    "- amount of compute used at *test/inference* time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Increasing Performance by increasing compute at inference time\n",
    "\n",
    "There are several techniques for improving Performance by using more resources at inference time.\n",
    "\n",
    "- *Test-time scaling*\n",
    "- *Reasoning*: Training a model to \"think\" longer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*Test-time scaling* refers to\n",
    "- increasing resources purely at inference time\n",
    "\n",
    "This is often manifested \n",
    "- using a pre-trained LLM as a \"subroutine\" in a control program\n",
    "- enabling the LLM to produce multiple candidate answers\n",
    "- which are filtered into a final answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*Reasoning*\n",
    "- uses *training-time* resources\n",
    "- to train an LLM to produce longer answers\n",
    "    - which also results in more test-time compute being consumed\n",
    "    \n",
    "These longer answers are not merely increasing verbosity\n",
    "- they encourage the LLM to generate a plan for creating an answer\n",
    "- which culminates in the final answer\n",
    "\n",
    "The plan increases the probability that the final answer is correct (increase in the Performance metric).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "These two methods may be combined\n",
    "- training a model to Reason\n",
    "    - using training-time compute\n",
    "- using test-time strategies to augment the reasoning\n",
    "    - searching for the best answer among multiple candidate, where each candidate answer uses reasoning\n",
    "    - guiding the reasoning process\n",
    "        - *back-tracking* when a reasoning trace appears unlikely to succeed\n",
    "        - encouraging *revision* and *reflection*\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We will devote a separate module to Reasoning.\n",
    "\n",
    "This module will focus on pure test-time increases in compute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Test-time scaling\n",
    "\n",
    "We first focus on pure test-time increases in compute\n",
    "- with no pre-training that uses additional training-time compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## An LLM can produce more than one solution\n",
    "\n",
    "When predicting the next token (using a Transformer in auto-regressive mode)\n",
    "the Language Model outputs\n",
    "\n",
    "$$\n",
    "\\pr{\\y_\\tp \\, | \\, \\y_{(1:\\tt-1)}}\n",
    "$$\n",
    "\n",
    "- a *probability distribution*\n",
    "- from which we sample a single token $\\y_\\tp$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If we sample deterministically\n",
    "$$\n",
    "\\hat\\y_\\tp = \\Vocab_{j^*} \\text{ where } j^* = \\argmax{ j }{ \\pr{\\y_\\tp \\, | \\, \\y_{(1:\\tt-1)}}_j}\n",
    "$$\n",
    "- i.e., the token in vocabulary $\\Vocab$ with the greatest probability in probability vector $\\pr{\\y_\\tp \\, | \\, \\y_{(1:\\tt-1)}}$ \n",
    "- the next token is unique\n",
    "- the answer sequence $\\y$ is unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "But if we sample according to the probabilities $\\pr{\\y_\\tp \\, | \\, \\y_{(1:\\tt-1)}}$\n",
    "- there are many possible answer sequences $\\y$\n",
    "\n",
    "- some of them syntactically different but with the same answer\n",
    "- some with different answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Thus, it is possible to use compute at test time to generate more than one answer to a prompt.\n",
    "\n",
    "There are several strategies for using multiple answers to improve Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multiple answer attempts can improve Performance\n",
    "\n",
    "Suppose we allow the LLM multiple attempts at producing an answer.\n",
    "\n",
    "Is is likely that one of the candidate answers is the correct one ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "Suppose we sample $k$ answers and have a method for identifying the \"best\".\n",
    "\n",
    "How does that affect Performance ?\n",
    "\n",
    "Rather than grading the response to a prompt with a binary Pass/Fail grade\n",
    "- Define *pass@k* to be true if one of the $k$ candidate answers is correct.\n",
    "\n",
    "We examine how *pass@k* varies with increasing $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <center><strong>Coverage vs. number of samples</strong></center>\n",
    "    <tr>\n",
    "        <img src=\"images/LargeLanguageMonkeys_performance_vs_samples.png\">\n",
    "    </tr>\n",
    "    \n",
    "Attribution: https://arxiv.org/pdf/2407.21787#page=5\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The chart shows that\n",
    "- if we can identify the correct answers from among the $k$ candidates\n",
    "- increasing Performance $P(k)$ by a constant increment $\\alpha$\n",
    "- requires an exponential increase in $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "That is\n",
    "$$\n",
    "P(k) = \\alpha \\log_b k\n",
    "$$\n",
    "so increasing $k$ to $b*k$ boost Performance to $P(k) + \\alpha$\n",
    "$$\n",
    "    \\begin{array} \\\\\n",
    "       P(k*b) &  = & \\alpha \\log_b k*b \\\\\n",
    "       & = & \\alpha * (\\log_b k + 1) \\\\\n",
    "       & = & P(k) + \\alpha \\\\\n",
    "    \\end{array}\n",
    "$$\n",
    "\n",
    "For example, referring to the above chart (right side, bottom row/left column)\n",
    "- for MATH (Oracle Verifier) Llama-3-8B **blue line**\n",
    "    - increasing Coverage from $0.25$ to $0.5$\n",
    "    - requires increasing $k$ from $10^0  = 1$ to $10^1$\n",
    "\n",
    "So test-time compute can be effective, but quite expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Test-time Scaling Law\n",
    "\n",
    "The simplest description of the Test-time Scaling law is the following chart\n",
    "- Performance\n",
    "- versus Compute Budget\n",
    "    - log scale for compute \"thinking time\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <center><strong>\n",
    "        Test-Time Scaling Law\n",
    "        <br>\n",
    "        as function of length of reasoning trace\n",
    "        </strong></center>\n",
    "    <tr>\n",
    "        <img src=\"images/s1_scaling_compressed.png\" width=85%>\n",
    "    </tr>\n",
    "    \n",
    "Attribution: https://arxiv.org/pdf/2501.19393#page=1\n",
    "\n",
    "(Note the horizontal scale is logarithmic)\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Note that the horizontal axis is $\\log_2$ scale.\n",
    "\n",
    "So the Scaling Law says that\n",
    "- Performance is log-linear in Compute Budget\n",
    "- so increasing Performance by a constant increment requires an exponential increase in compute\n",
    "\n",
    "This is very expensive !\n",
    "\n",
    "We will examine this in more detail below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scaling alternatives: Test-time versus Model Size\n",
    "\n",
    "How does scaling via Test-Time compute\n",
    "- compare to scaling by increasing the number of parameters ?\n",
    "    - using training-time compute rather than test-time compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The chart below compares the Performance of \n",
    "- a small model using Test-Time Compute\n",
    "- a model 14 times larger in parameters that only uses pre-training (no test-time compute)\n",
    "\n",
    "when both models use the *same compute budget* (FLOPS-matched)\n",
    "- the small model uses the budget at test-time\n",
    "- the large model uses the budget only at train-time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <center><strong>Test Time Scaling Law\n",
    "        <br>\n",
    "        and \n",
    "        <br>\n",
    "        Comparison of using Compute Budget at Train-time (big model) vs Compute-time (small model)\n",
    "        <br>\n",
    "        as the difficulty of a problem varies\n",
    "        </strong></center>\n",
    "    <tr>\n",
    "        <img src=\"images/Scaling_TestTimeCompute_Optimally_summary.png\">\n",
    "    </tr>\n",
    "    \n",
    "Attribution: https://arxiv.org/pdf/2408.03314v1#page=15\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Interpeting the chart**\n",
    "\n",
    "Problem instances are assigned \"difficulty bins\"\n",
    "- each trace represents one level of difficulty\n",
    "- difficulty represented by colors\n",
    "    - lower traces are the *harder* problems\n",
    "    - purple: easy\n",
    "    - blue: hard\n",
    "    \n",
    "\n",
    "For each difficulty level (color)\n",
    "- the trace with the solid line represents the small model (test-time compute)\n",
    "- the stars represent the big model (train-time compute)\n",
    "\n",
    "So the two traces of the same color\n",
    "- show the trade-off between Performance and Compute of the test-time compute model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "When the horizontal stars of one color\n",
    "- are below the trace of the same color\n",
    "- spending the compute budget on test-time yields better Performance than spending it at train-time\n",
    "\n",
    "For the Revisions method (left chart)\n",
    "- test-time compute yields better Performance\n",
    "- for the two *least difficult* classes of examples (purple and red)\n",
    "- but as difficult level increases (lower traces)\n",
    "    - big models with more train-time compute\n",
    "    - perform better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To summarize\n",
    "- there is a log-linear relationship between Performance and Compute\n",
    "- which is worthwhile for *less difficult* problems\n",
    "    - but for *more difficult* problems: \n",
    "        - larger models (with more train-time compute) are still needed \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Strategies for using test-time compute\n",
    "\n",
    "The above shows the potential for improving Performance by using test-time compute\n",
    "\n",
    "We examine several common strategies that can be used at test-time to improve Performance.\n",
    "\n",
    "They fall into two broad classes\n",
    "- Search\n",
    "- Reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Search\n",
    "\n",
    "We use the term \"search\" to describe \n",
    "- strategies that explore the space of possible answers\n",
    "\n",
    "These approaches use an external control process\n",
    "- to invoke the LLM multiple times\n",
    "- using logic to control the input to each invocation of the LLM\n",
    "\n",
    "The model is\n",
    "- used as a \"subroutine\" by the external \"control\" process\n",
    "- rather than being trained to perform the search directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Given that a correct answer to our prompt exists: how can we attempt to find it ?\n",
    "\n",
    "The following chart illustrates some strategies\n",
    "- to be discussed in subsequent sub-sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "\n",
    "<table>\n",
    "    <center><strong>Search Strategies</strong></center>\n",
    "    <tr>\n",
    "        <img src=\"images/Scaling_TestTimeCompute_Optimally_search.png\">\n",
    "    </tr>\n",
    "    \n",
    "Attribution: https://arxiv.org/pdf/2408.03314v1#page=8\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Some strategies result in multiple candidate solutions.\n",
    "\n",
    "How do we decide the single final answer ?\n",
    "\n",
    "That too will be discussed after presenting the strategies for generating the candidates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parallel search\n",
    "\n",
    "Parallel search\n",
    "- independently samples multiple answers\n",
    "    - run the non-deterministic LLM multiple times\n",
    "    - starting from the same initial state (e.g., random seed)\n",
    "\n",
    "The left-most example in the chart illustrates this approach.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Systematic search\n",
    "\n",
    "Rather than sampling complete answers independently\n",
    "- one can imagine a systematic search of the answer space\n",
    "- generating intermediate (non-final) answers\n",
    "- deciding which intermediate answers to improve/which to kill\n",
    "\n",
    "This is a type of parallel approach, where the answers are not independently generated.\n",
    "\n",
    "This results in a tree-like structure\n",
    "- where the leaves are the candidate final answers\n",
    "\n",
    "The center and right-most example in the chart illustrates this approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sequential search via Revision\n",
    "\n",
    "\n",
    "<table>\n",
    "    <center><strong>Revision strategies</strong></center>\n",
    "    <tr>\n",
    "        <img src=\"images/Scaling_TestTimeCompute_Optimally_revisions.png\">\n",
    "    </tr>\n",
    "    \n",
    "Attribution: https://arxiv.org/pdf/2408.03314v1#page=11\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Sequential revisions** (above chart lower left and upper right)\n",
    "\n",
    "Here we use the LLM multiple times *sequentially* to generate a final answer\n",
    "- the $i^{th}$ answer is critiqued by the LLM\n",
    "- and used to create a *revised* successor answer $i+1$\n",
    "    - the successor is not necessarily \"better\", just a result of responding to the critique\n",
    "\n",
    "Note\n",
    "- \"parallel\" revision is just \"Best-of-N\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reducing multiple candidate answers to a single final answer\n",
    "\n",
    "Some search strategies result in multiple candidate answers.\n",
    "\n",
    "There are several strategies for reducing to a single, final answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Majority vote\n",
    "\n",
    "Generate $N$ candidates\n",
    "- select the candidate that occurs most frequently among the $N$ candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "###  Using ranking\n",
    "\n",
    "The following strategies require the ability to rank the candidates\n",
    "- may be a partial order, rather than a total order\n",
    "\n",
    "The section on Verifiers expands on this idea.\n",
    "\n",
    "For now: we show how ranking may be used to reduce the set of candidates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Best-of-N\n",
    "\n",
    "Generate $N$ candidates\n",
    "- select the single \"best\" candidate as the final answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Beam Search \n",
    "\n",
    "This adapts the search to incorporate the ability to rank *partial* answers.\n",
    "\n",
    "Generate $N$ candidates at each step\n",
    "- Select the $M$ (the *beam width*) best answers to continue to explore\n",
    "- Repeat with the $M$ surviving candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Verifiers: Identifying the \"best\" candidate\n",
    "\n",
    "Given a collection of candidates, how do we identify the best ?\n",
    "\n",
    "For certain tasks:\n",
    "- We create a mechanism  called a *Verifier*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <center><strong>Sampling answers</strong></center>\n",
    "    <tr>\n",
    "        <img src=\"images/LargeLanguageMonkeys_sample.png\">\n",
    "    </tr>\n",
    "    \n",
    "Attribution: https://arxiv.org/pdf/2407.21787#page=3\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For certain tasks\n",
    "- it is difficult to *efficiently* discover an answer (i.e., not brute-force search)\n",
    "- but easy to verify whether a candidate is correct\n",
    "\n",
    "For example\n",
    "- it is expensive to find Prime numbers\n",
    "- but easy to verify whether a candidate is Prime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "When Verification is possible\n",
    "- rank candidates with correct answers higher than candidates with incorrect answers\n",
    "\n",
    "But among multiple correct candidates, a *subjective* mechanism may be needed to choose\n",
    "- e.g., for a task requiring the construction of a proof of a Theorem\n",
    "- a shorter correct proof may be more desirable than a longer (but still correct) proof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Limits on Verification\n",
    "\n",
    "The use of Verifiers is limited by the task\n",
    "- Math problems are often verifiable\n",
    "    - test the correctness of the answer\n",
    "- Text problems are often *not verifiable*\n",
    "    - Performance is subjective\n",
    "    - human preference as the which is the \"best\" answers\n",
    "        - e.g., which summary of a long academic paper is best ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reward models\n",
    "\n",
    "\n",
    "For tasks where  Verification is not possible (or results in ties)\n",
    "- we train a Neural Network to rank candidates\n",
    "- generating a \"reward\" for each candidate.\n",
    "\n",
    "These models are trained using examples created by Human Feedback\n",
    "- Human prompts an LLM to generate multiple answers to a problem\n",
    "- Human ranks the answers (really: creates pairs of candidates and identifies the preferred one)\n",
    "- Neural Network Classifier trained to identify the preferred candidate in the pair\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A verifier which is used to verify/rank only *complete* candidate answers\n",
    "- is called an *Output Reward Model (ORM)*\n",
    "\n",
    "These can be used to rank the multiple candidates as required\n",
    "by some of the above strategies for producing candidate answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "More sophisticated reward models\n",
    "- can be used to *guide* the search\n",
    "- by evaluating each step in the generation of a single candidate answer.\n",
    "\n",
    "Such models are called\n",
    "*Process Reward Models (PRM)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "These are commonly used when the answers contain *chains of thought/reasoning*\n",
    "\n",
    "- a PRM can assign a score to *each reasoning step*\n",
    "    - can terminate a branch of the search upon discovering an incorrect reasoning step\n",
    "    - can choose which branches to extend by ranking the quality of the reasoning\n",
    "        - can be combined with back-tracking\n",
    "\n",
    "A candidate with a fatally incorrect reasoning step has a low reward.\n",
    "\n",
    "A candidate with a correct answer has a higher reward\n",
    "- can combine the per-step rewards into a final reward/score for the candidate\n",
    "- choose as final answer the candidate with highest reward\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reasoning\n",
    "\n",
    "The second approach\n",
    "- trains a model\n",
    "- to use a \"Chain of Thought\" solution strategy\n",
    "    - producing a final answer\n",
    "    - as the culmination of a process of \"thinking step by step\"\n",
    "    - that culminates in a final answer\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The model produces the answer on its own\n",
    "- no external control process\n",
    "- using solution strategies that it has been trained (via examples) to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Reasoning can also involve *strategies* that lead to better solutions\n",
    "\n",
    "Some useful strategies\n",
    "- *revision*\n",
    "    - abandon an intermediate solution\n",
    "    - change the intermediate solution and extend\n",
    "    \n",
    "- *reflection* \n",
    "    - \"reflect on\" (i.e., evaluate)\n",
    "    - intermediate solutions (reasoning traces that have not yet created an answer)\n",
    "    - to determine whether the reasoning trace is on \"the right track\" to a good solution\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Combining training-time and test-time methods for increasing Performance\n",
    "\n",
    "In theory\n",
    "- we could train the model to use long Chain of Thought reasoning traces\n",
    "- use the reasoning model as a \"subroutine\" in a test-time process as in Test-time scaling\n",
    "\n",
    "Strategies such as Reflection and Revision\n",
    "- could be implemented as part of the test-time control program\n",
    "- or *instilled into the model* as part of training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3.9 (new)",
   "language": "python",
   "name": "new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "343px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
